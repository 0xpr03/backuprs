# Rename this to config.toml

[global]
# Path to restic binary
restic_binary = "C:/restic_0.15.1_windows_amd64/restic_0.15.1_windows_amd64.exe"
# Default intervall for jobs in minutes
default_interval = 720
# Directory used for database files created during backup creation
scratch_dir = "scratchdir"

# mysql dumb binary, if used for database backups, can be left blank if available in path
# mysql_dumb_binary = "C:/Program Files/mysql/mysqldump.exe"

# postgres dumb binary, if used for database backups, can be left blank if available in path
# postgres_dumb_binary = "C:/Program Files/PostgreSQL/14/bin/pg_dump.exe"

# [global.period]
# Optionally limit backup scheduling to the following time frame
# start time
# backup_start_time = "22:00"
# end time
# backup_end_time = "05:00"

# Rest-Server as backend
[global.Rest]
# URL for rest server to use for all jobs
# only domain:port or ip:port
rest_host = "example.com:443"
# Pubkey of restic server
server_pubkey_file = "C:/Users/Foo/pub_key"

# SFTP as backend
[global.SFTP]
# URL for rest server to use for all jobs
# only domain:port or ip:port
sftp_host = "example.com:443"
# Optional command for connecting with special settings.
# For restic option `-o sftp.command="ssh -p 22 u1234@u1234.example.com -s sftp"`
# can contain {user} to be replaced by job user
# can contain {host} to be replaced by default or job override host
sftp_command = "ssh -p 22 {user}@{host} -s sftp"

# S3 as backend
[global.S3]
# URL for rest server to use for all jobs
# only domain:port or ip:port
s3_host = "s3.amazonaws.com"

# All backup jobs, start each one with [[jobs]]
[[job]]
# For referencing jobs in commands and output, also used as part of the database backup folder
name = "Job1"
# Command to run pre backup
# pre_command = ""
# Paths to include for backup
# Use only / for delimiters
paths = ["C:/Users/Foo"]
# Exclude items see [restic docs](https://restic.readthedocs.io/en/latest/040_backup.html#excluding-files)
excludes = []

# Encryption key
repository_key = "<CHANGE ME>"
# Repository name
repository = "<CHANGE ME>"
# Command to run post backup
# post_command = { command = "", args= ["foo","bar"] }
# Whether to run the post_command even on backup failure
post_command_on_failure = false
# custom interval for this job, in minutes
# interval = 1440
# Postgres Database backup
# postgres_db = {database = "database", change_user = false, user = "user", password = "password"}
# MySQL Database backup
# mysql_db = "database"

[job.Rest]
# Login user
rest_user = "<CHANGE ME>"
# Password for user
rest_password = "<CHANGE ME>"

# a second job, minimal required settings
[[job]]
name = "Job2"
paths = ["C:/Users/Foo"]
excludes = []
repository_key = "<CHANGE ME>"
repository = "<CHANGE ME>"
post_command_on_failure = false

[job.SFTP]
sftp_user = "<CHANGE ME>"
# optional, can contain {user} and {host}
sftp_command = "ssh -p 22 {user}@{host} -s sftp"

# third job, mysql backup only
[[job]]
name = "Job3"
paths = []
excludes = []

repository_key = "<CHANGE ME>"
repository = "<CHANGE ME>"
mysql_db = "database"
post_command_on_failure = false

[job.S3]
aws_access_key_id = "<CHANGE ME>"
aws_secret_access_key = "<CHANGE ME>"